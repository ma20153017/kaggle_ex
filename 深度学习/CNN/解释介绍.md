以下为基于PyTorch实现CNN模型的完整技术说明，包含核心理论、计算公式及代码实现细节。内容整合了前向传播、反向传播、正则化等关键技术点，适用于MNIST等图像分类任务。

---

一、卷积神经网络核心理论
1.1 前向传播机制
卷积层通过局部感受野提取空间特征，其多通道计算式如所示：
\[ Y(c_o,i,j)=\sigma \left(b_{c_o} + \sum_{c_i=0}^{C_i-1}\sum_{k=0}^{K-1}\sum_{l=0}^{L-1} X(c_i,i+k,j+l)\cdot W(c_o,c_i,k,l)\right) \]
其中：
• \(C_i/C_o\)：输入/输出通道数

• \(K/L\)：卷积核高宽

• \(\sigma\)：激活函数（常用ReLU）


池化层采用最大池化公式：
\[ Pool(x)_{i,j} = \max_{m,n \in \text{窗口}}(x_{i+m,j+n}) \]

1.2 反向传播原理
梯度计算遵循链式法则，卷积层的权重梯度公式：
\[ \frac{\partial E}{\partial W(c_o,c_i,h,w)} = \sum_{m,n} \delta(m,n) \times I(c_i,m+h,n+w) \]
其中：
• \(\delta\)：上层传递的梯度误差

• \(I\)：输入特征图局部区域


全连接层梯度计算式：
\[ \frac{\partial L}{\partial W^{(2)}} = \frac{\partial L}{\partial o} \cdot h^T \]
\[ \frac{\partial L}{\partial W^{(1)}} = \frac{\partial L}{\partial h} \cdot X^T \]

---

二、PyTorch实现代码（带理论注释）
```python
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

#%% [1. 数据加载与预处理]
# 理论：归一化使数据分布均值为0，标准差1，加速收敛
try:
    # 加载训练数据（假设为[0,255]范围）
    train_images = torch.load('train-images.pt')  # shape [60000,28,28]
    train_labels = pd.read_csv('train-labels.csv').values[:,0]
except FileNotFoundError as e:
    print(f"文件加载错误: {e}")

# 添加通道维度并归一化
images = train_images.unsqueeze(1).float()  # [N,1,28,28]
images = (images/255.0 - 0.5)/0.5  # 归一化到[-1,1]

# 转换为TensorDataset
dataset = TensorDataset(images, torch.LongTensor(train_labels))

# 8:2划分训练验证集
train_size = int(0.8 * len(dataset))
train_set, val_set = torch.utils.data.random_split(dataset, [train_size, len(dataset)-train_size])

#%% [2. CNN模型定义]
class LeNet(nn.Module):
    def __init__(self):
        super().__init__()
        # 卷积层组（特征提取）
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, 3, padding=1),  # 输入通道1，输出32
            nn.ReLU(),
            nn.MaxPool2d(2),  # 输出16x16
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)   # 输出7x7
        )
        # 分类器（全连接层）
        self.classifier = nn.Sequential(
            nn.Linear(64*7*7, 256),
            nn.ReLU(),
            nn.Dropout(0.5),  # 防止过拟合
            nn.Linear(256, 10)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)  # 展平特征图
        return self.classifier(x)

#%% [3. 训练配置]
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = LeNet().to(device)

# 损失函数：交叉熵（含Softmax）
criterion = nn.CrossEntropyLoss()  
# 优化器：Adam + L2正则化
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)

#%% [4. 训练循环]
for epoch in range(5):
    # 训练阶段
    model.train()
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        
        # 前向传播
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        
        # 反向传播（自动计算梯度）
        optimizer.zero_grad()
        loss.backward()  # 反向传播计算梯度
        optimizer.step()  # 参数更新

    # 验证阶段
    model.eval()
    with torch.no_grad():
        total_correct = 0
        for inputs, labels in val_loader:
            outputs = model(inputs.to(device))
            total_correct += (outputs.argmax(1) == labels.to(device)).sum().item()
        val_acc = total_correct / len(val_set)
```

---

三、关键公式与优化策略
3.1 正则化方法
• L2正则化：在损失函数中添加权重平方项

\[ L_{reg} = L + \lambda \sum w^2 \]
• Dropout：前向传播时随机屏蔽神经元

\[ h_i^{drop} = h_i \cdot \text{Bernoulli}(p) \]

3.2 学习率调整
采用指数衰减策略：
\[ \eta_t = \eta_0 \cdot \gamma^{t} \]
其中\(\gamma\)为衰减系数，建议取值0.95-0.99

---

四、例外处理与优化建议
1. 显存不足：
   • 减小`batch_size`（如128→64）

   • 使用`torch.utils.checkpoint`分段计算


2. 验证集波动大：
   • 增加数据增强（旋转、平移）

   • 启用早停机制（连续3个epoch无改进则终止）


3. 预测结果单一类别：
   • 检查标签分布是否均衡

   • 添加类别权重：

     ```python
     class_weights = torch.tensor([1.0/cls_count for cls_count in class_counts])
     criterion = nn.CrossEntropyLoss(weight=class_weights)
     ```

---

五、测试阶段注意事项
```python
# 必须使用与训练相同的预处理！
test_images = (torch.load('test_images.pt').unsqueeze(1)/255.0 - 0.5)/0.5

model.eval()
with torch.no_grad():
    outputs = model(test_images.to(device))
    predictions = outputs.argmax(1).cpu().numpy()

pd.DataFrame({'label': predictions}).to_csv('submission.csv', index_label='id')
```
关键点：
• 测试数据归一化参数需与训练一致

• 输出前确认模型处于`eval`模式（关闭Dropout）

• 文件保存格式需符合竞赛要求（通常为CSV）
